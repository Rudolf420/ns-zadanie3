{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b4fd8a4-de3a-4819-becc-9ef5be44870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba4c4e-5400-4b5d-a1f5-07175f4c851d",
   "metadata": {},
   "source": [
    "#### Tento kód načítava dataset CIFAR-10, konvertuje obrázky na stupne grayscale, normalizuje hodnoty pixelov medzi -1 a 1 a rozdeľuje dataset na trénovaciu a validačnú časť. Obrázky v stupňoch grayscale sú preformátované na 4D tenzory s jedným kanálom, a farebné obrázky sú preformátované na 4D tenzory s tromi kanálmi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57a68ae2-6206-4672-80f5-cefd5d2eddeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "EagerTensor object has no attribute 'astype'. \n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()\n      ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m X_test_gray \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mrgb_to_grayscale(X_test)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Normalize pixel values between -1 and 1\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m X_train_gray \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_gray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m X_train_gray \u001b[38;5;241m=\u001b[39m (X_train_gray \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m127.5\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     11\u001b[0m X_test_gray \u001b[38;5;241m=\u001b[39m X_test_gray\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:440\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m    437\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    438\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;124m      If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;124m      from tensorflow.python.ops.numpy_ops import np_config\u001b[39m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;124m      np_config.enable_numpy_behavior()\u001b[39m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m    446\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: EagerTensor object has no attribute 'astype'. \n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()\n      "
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Convert images to grayscale\n",
    "x_train_gray = np.dot(x_train, [0.299, 0.587, 0.114])\n",
    "x_test_gray = np.dot(x_test, [0.299, 0.587, 0.114])\n",
    "\n",
    "# Normalize pixel values between -1 and 1\n",
    "x_train_gray = (x_train_gray / 255.0) * 2 - 1\n",
    "x_test_gray = (x_test_gray / 255.0) * 2 - 1\n",
    "\n",
    "# Reshape grayscale images to 4D tensors with a single channel\n",
    "x_train_gray = x_train_gray.reshape(x_train_gray.shape[0], 32, 32, 1)\n",
    "x_test_gray = x_test_gray.reshape(x_test_gray.shape[0], 32, 32, 1)\n",
    "\n",
    "# Reshape color images to 4D tensors with 3 channels\n",
    "x_train_color = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
    "x_test_color = x_test.reshape(x_test.shape[0], 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f665e87-f830-43ed-9c88-50769aa782c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LeakyReLU, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Define generator network architecture\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(32, 32, 1)),\n",
    "        layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2DTranspose(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2DTranspose(3, kernel_size=3, padding=\"same\", activation=\"tanh\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "# Define discriminator network architecture\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(32, 32, 3)),\n",
    "        layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Conv2D(256, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Define combined model architecture\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "generator.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "discriminator.trainable = False\n",
    "gan_input = keras.Input(shape=(32, 32, 1))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output, name=\"gan\")\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4487af1f-8b38-4c2c-a98e-0df5e8f6bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 128\n",
    "sample_interval = 10\n",
    "num_batches = len(x_train_gray)// batch_size\n",
    "print(num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36c6d4f7-a811-420f-9eec-37fd913af41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(epoch):\n",
    "    # Generate images from random noise\n",
    "    noise = np.random.normal(0, 1, (16, 32, 32, 1))\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    # Rescale pixel values between 0 and 1\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "    # Plot generated images\n",
    "    fig, axs = plt.subplots(4, 4)\n",
    "    count = 0\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axs[i,j].imshow(generated_images[count, :, :, :])\n",
    "            axs[i,j].axis('off')\n",
    "            count += 1\n",
    "    plt.savefig(f\"{epoch}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79adf46d-397c-455e-9abe-7e192ad9f4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4893ff8-55c3-4fd5-8246-6be7c4e922a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "4/4 [==============================] - 0s 17ms/step\n",
      "128\n",
      "128 256\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 128\n  y sizes: 256\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x),\u001b[38;5;28mlen\u001b[39m(y))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Train the discriminator on the real and generated images\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m discriminator_loss \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Train the generator to fool the discriminator\u001b[39;00m\n\u001b[0;32m     21\u001b[0m noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, (batch_size, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2377\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m   2374\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   2375\u001b[0m     \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   2376\u001b[0m ):\n\u001b[1;32m-> 2377\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_batch_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\n\u001b[0;32m   2379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[0;32m   2381\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1831\u001b[0m, in \u001b[0;36msingle_batch_iterator\u001b[1;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1828\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1829\u001b[0m     data \u001b[38;5;241m=\u001b[39m (x, y, sample_weight)\n\u001b[1;32m-> 1831\u001b[0m \u001b[43m_check_data_cardinality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1832\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensors(data)\n\u001b[0;32m   1833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_weight:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1851\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1845\u001b[0m         label,\n\u001b[0;32m   1846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m   1847\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1848\u001b[0m         ),\n\u001b[0;32m   1849\u001b[0m     )\n\u001b[0;32m   1850\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1851\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 128\n  y sizes: 256\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch in range(num_batches):\n",
    "        # Select a random batch of grayscale images\n",
    "        real_images = x_train_gray[np.random.randint(0, x_train_gray.shape[0], batch_size)]\n",
    "        print(len(real_images))\n",
    "        # Generate a batch of color images from the grayscale images\n",
    "        generated_images = generator.predict(real_images)\n",
    "        print(len(generated_images))\n",
    "        # Concatenate the real and generated images into a single batch\n",
    "        #TODO error s axis\n",
    "        x = np.concatenate([real_images,generated_images])\n",
    "        # x = np.concatenate([generated_images],axis=3)\n",
    "        # Label the real and generated images\n",
    "        y_real = np.ones((batch_size, 1))\n",
    "        y_fake = np.zeros((batch_size, 1))\n",
    "        y = np.concatenate([y_real, y_fake])\n",
    "        print(len(x),len(y))\n",
    "        # Train the discriminator on the real and generated images\n",
    "        discriminator_loss = discriminator.train_on_batch(x, y)\n",
    "\n",
    "        # Train the generator to fool the discriminator\n",
    "        noise = np.random.normal(0, 1, (batch_size, 32, 32, 1))\n",
    "        generator_loss = gan.train_on_batch(noise, y_real)\n",
    "\n",
    "    # Print the epoch number and losses\n",
    "    print(f\"Epoch {epoch+1}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}\")\n",
    "\n",
    "    # Save sample images\n",
    "    if epoch % sample_interval == 0:\n",
    "        sample_images(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e24c692-debd-4c81-8239-06c22988a2b0",
   "metadata": {},
   "source": [
    "### Trénovavanie GAN modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a4999-d5a2-41ac-b4fc-1d0f0e15dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epochs, batch_size, sample_interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
